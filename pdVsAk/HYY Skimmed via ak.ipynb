{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<CENTER><img src=\"../../images/ATLASOD.gif\" style=\"width:50%\"></CENTER>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to rediscover the Higgs boson yourself!\n",
    "This notebook uses ATLAS Open Data http://opendata.atlas.cern to show you the steps to rediscover the Higgs boson yourself!\n",
    "\n",
    "ATLAS Open Data provides open access to proton-proton collision data at the LHC for educational purposes. ATLAS Open Data resources are ideal for high-school, undergraduate and postgraduate students.\n",
    "\n",
    "Notebooks are web applications that allow you to create and share documents that can contain for example:\n",
    "1. live code\n",
    "2. visualisations\n",
    "3. narrative text\n",
    "\n",
    "This analysis loosely follows the discovery of the Higgs boson by ATLAS https://arxiv.org/pdf/1207.7214.pdf (mostly Section 5 and 5.1)\n",
    "\n",
    "By the end of this notebook you will be able to:\n",
    "1. rediscover the Higgs boson yourself!\n",
    "2. know some general principles of a particle physics analysis\n",
    "\n",
    "Feynman diagram pictures are borrowed from our friends at https://www.particlezoo.net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<CENTER><img src=\"images/feynman_diagrams/Hyy_feynman.png\" style=\"width:40%\"></CENTER>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='contents'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contents: \n",
    "\n",
    "[Running a Jupyter notebook](#running) <br />\n",
    "[First time setup on your computer (no need on mybinder)](#setup_computer) <br />\n",
    "[To setup everytime](#setup_everytime) <br />\n",
    "[Lumi, fraction, file path](#fraction) <br />\n",
    "[Samples](#samples) <br />\n",
    "[Changing a cut](#changing_cut) <br />\n",
    "[Applying a cut](#applying_cut) <br />\n",
    "[Plotting](#plotting) <br />\n",
    "[What can you do to explore this analysis?](#going_further) <br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='running'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running a Jupyter notebook\n",
    "\n",
    "To run the whole Jupyter notebook, in the top menu click Cell -> Run All.\n",
    "\n",
    "To propagate a change you've made to a piece of code, click Cell -> Run All Below.\n",
    "\n",
    "You can also run a single code cell, by clicking Cell -> Run Cells, or using the keyboard shortcut Shift+Enter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='setup_computer'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First time setup on your computer (no need on mybinder)\n",
    "This first cell only needs to be run the first time you open this notebook on your computer. \n",
    "\n",
    "If you close Jupyter and re-open on the same computer, you won't need to run this first cell again.\n",
    "\n",
    "If you open on binder, you don't need to run this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import sys\n",
    "#!{sys.executable} -m pip install --upgrade --user pip # update the pip package installer\n",
    "#!{sys.executable} -m pip install -U numpy==2.0.0 pandas==2.2.2 uproot==5.3.9 matplotlib==3.9.0 lmfit==1.3.1 awkward-pandas==2023.8.0 aiohttp==3.9.5 requests==2.32.3 --user # install required packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='setup_everytime'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To setup everytime\n",
    "Cell -> Run All Below\n",
    "\n",
    "to be done every time you re-open this notebook\n",
    "\n",
    "We're going to be using a number of tools to help us:\n",
    "* uproot: lets us read .root files typically used in particle physics into data formats used in python\n",
    "* pandas: lets us store data as dataframes, a format widely used in python\n",
    "* numpy: provides numerical calculations such as histogramming\n",
    "* matplotlib: common tool for making plots, figures, images, visualisations\n",
    "* lmfit: tool for statistical fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install lmfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install awkward-pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import uproot # for reading .root files\n",
    "import awkward as ak \n",
    "import time # to measure time to analyse\n",
    "import math # for mathematical functions such as square root\n",
    "import numpy as np # # for numerical calculations such as histogramming\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "from matplotlib.ticker import MaxNLocator,AutoMinorLocator # for minor ticks;\n",
    "from lmfit.models import PolynomialModel, GaussianModel # for the signal and background fits\n",
    "import requests # for HTTP access\n",
    "import aiohttp # HTTP client support\n",
    "import vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check tree content of old and new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108492747\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ScaleFactor_PILEUP',\n",
       " 'mcWeight',\n",
       " 'xsec',\n",
       " 'trigE',\n",
       " 'trigM',\n",
       " 'ScaleFactor_BTAG',\n",
       " 'jet_n',\n",
       " 'jet_pt',\n",
       " 'jet_eta',\n",
       " 'jet_phi',\n",
       " 'jet_e',\n",
       " 'jet_DL1d77_isBtagged',\n",
       " 'jet_jvt',\n",
       " 'largeRJet_n',\n",
       " 'largeRJet_pt',\n",
       " 'largeRJet_eta',\n",
       " 'largeRJet_phi',\n",
       " 'largeRJet_e',\n",
       " 'largeRJet_m',\n",
       " 'largeRJet_D2',\n",
       " 'ScaleFactor_ELE',\n",
       " 'ScaleFactor_MUON',\n",
       " 'lep_n',\n",
       " 'lep_type',\n",
       " 'lep_pt',\n",
       " 'lep_eta',\n",
       " 'lep_phi',\n",
       " 'lep_e',\n",
       " 'lep_charge',\n",
       " 'lep_ptvarcone30',\n",
       " 'lep_topoetcone20',\n",
       " 'lep_z0',\n",
       " 'lep_d0',\n",
       " 'lep_d0sig',\n",
       " 'lep_isTight',\n",
       " 'lep_isTightID',\n",
       " 'lep_isTightIso',\n",
       " 'ScaleFactor_PHOTON',\n",
       " 'photon_n',\n",
       " 'photon_pt',\n",
       " 'photon_eta',\n",
       " 'photon_phi',\n",
       " 'photon_e',\n",
       " 'photon_ptcone20',\n",
       " 'photon_topoetcone40',\n",
       " 'photon_isTight',\n",
       " 'photon_isTightID',\n",
       " 'photon_isTightIso',\n",
       " 'ScaleFactor_TAU',\n",
       " 'tau_n',\n",
       " 'tau_pt',\n",
       " 'tau_eta',\n",
       " 'tau_phi',\n",
       " 'tau_e',\n",
       " 'tau_charge',\n",
       " 'tau_nTracks',\n",
       " 'tau_isTight',\n",
       " 'tau_RNNJetScore',\n",
       " 'tau_RNNEleScore',\n",
       " 'met',\n",
       " 'met_phi',\n",
       " 'met_mpx',\n",
       " 'met_mpy']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new file\n",
    "pname = '/project/etp1/dkoch/ATLASOpenData/ntuples-data-samples/data15_allyear.root'\n",
    "pname = '/project/etp1/dkoch/ATLASOpenData/ntuples-data-samples/data16_allyear_G.root'\n",
    "tree = uproot.open(pname+':analysis')\n",
    "\n",
    "print(tree.num_entries)\n",
    "\n",
    "tree.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data15_periodD', 'data15_periodG', 'data16_periodA', 'data16_periodD', 'data16_periodG', 'data16_periodL', 'data15_periodE', 'data15_periodH', 'data16_periodB', 'data16_periodE', 'data16_PeriodI', 'data15_periodF', 'data15_periodJ', 'data16_periodC', 'data16_periodF', 'data16_periodK']\n",
      "Total number of entries: 4998873\n"
     ]
    }
   ],
   "source": [
    "import uproot\n",
    "\n",
    "# Define the path to the directory and the list of samples\n",
    "tuple_path = \"/project/etp1/dkoch/ATLASOpenData/ntuples-data-samples/\"\n",
    "tuple_path = \"/project/etp1/dkoch/ATLASOpenData/GamGam/Data/\"\n",
    "\n",
    "\n",
    "\n",
    "samples_list = ['data15_allyear', 'data16_allyear_A', 'data16_allyear_B', \n",
    "                'data16_allyear_C', 'data16_allyear_D', 'data16_allyear_E', \n",
    "                'data16_allyear_F', 'data16_allyear_G', 'data16_allyear_H']\n",
    "\n",
    "\n",
    "samples_list = [\n",
    "    'data15_periodD', 'data15_periodG', 'data16_periodA', 'data16_periodD', 'data16_periodG', 'data16_periodL',\n",
    "    'data15_periodE', 'data15_periodH', 'data16_periodB', 'data16_periodE', 'data16_PeriodI',\n",
    "    'data15_periodF', 'data15_periodJ', 'data16_periodC', 'data16_periodF', 'data16_periodK'\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "print(samples_list)\n",
    "\n",
    "\n",
    "\n",
    "# Initialize a variable to store the total number of entries\n",
    "total_entries = 0\n",
    "\n",
    "# Iterate through each sample in the list\n",
    "for sample in samples_list:\n",
    "    # Construct the full path to the .root file\n",
    "    pname = f\"{tuple_path}{sample}.root\"\n",
    "    \n",
    "    try:\n",
    "        # Open the .root file and access the 'analysis' tree\n",
    "        with uproot.open(pname + ':analysis') as tree:\n",
    "            # Add the number of entries in the current tree to the total\n",
    "            total_entries += tree.num_entries\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {pname}: {e}\")\n",
    "\n",
    "# Print the total number of entries across all samples\n",
    "print(f\"Total number of entries: {total_entries}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "myt = tree.iterate([\"photon_n\",\"photon_pt\",\"photon_eta\",\"photon_phi\",\"photon_e\",\n",
    "                            \"photon_isTightID\",\"photon_ptcone20\"], # add more variables here if you want to use them\n",
    "                           library=\"ak\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = next(myt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "no field named 'query'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[134], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mphoton_n>=2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/awkward/highlevel.py:1240\u001b[0m, in \u001b[0;36mArray.__getattr__\u001b[0;34m(self, where)\u001b[0m\n\u001b[1;32m   1235\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1236\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhile trying to get field \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwhere\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m, an exception \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1237\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moccurred:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(err)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1238\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1240\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno field named \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwhere\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: no field named 'query'"
     ]
    }
   ],
   "source": [
    "data = data.query('photon_n>=2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.photon_e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fraction'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lumi, fraction, file path\n",
    "\n",
    "General definitions of luminosity, fraction of data used, where to access the input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#lumi = 0.5 # fb-1 # data_A only\n",
    "#lumi = 1.9 # fb-1 # data_B only\n",
    "#lumi = 2.9 # fb-1 # data_C only\n",
    "#lumi = 4.7 # fb-1 # data_D only\n",
    "lumi = 10 # fb-1 # data_A,data_B,data_C,data_D\n",
    "MeV = 0.001\n",
    "GeV = 1\n",
    "fraction = 1 # reduce this is you want the code to run quicker\n",
    "\n",
    "#tuple_path = \"Input/GamGam/Data/\" # local \n",
    "tuple_path = \"/project/etp1/dkoch/ATLASOpenData/ntuples-data-samples/\"\n",
    "tuple_path = \"/project/etp1/dkoch/ATLASOpenData/GamGam/Data/\"\n",
    "#tuple_path = \"https://atlas-opendata.web.cern.ch/atlas-opendata/samples/2020/GamGam/Data/\" # web address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='samples'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Samples\n",
    "\n",
    "Samples to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#samples_list = ['data_A','data_B','data_C','data_D'] # add if you want more data\n",
    "samples_list = ['data15_allyear', 'data16_allyear_A', 'data16_allyear_B', \n",
    "                'data16_allyear_C', 'data16_allyear_D', 'data16_allyear_E', \n",
    "                'data16_allyear_F', 'data16_allyear_G', 'data16_allyear_H' ]\n",
    "#samples_list = ['data15_allyear']  \n",
    "samples_list = [\n",
    "    'data15_periodD', 'data15_periodG', 'data16_periodA', 'data16_periodD', 'data16_periodG', 'data16_periodL',\n",
    "    'data15_periodE', 'data15_periodH', 'data16_periodB', 'data16_periodE', 'data16_PeriodI',\n",
    "    'data15_periodF', 'data15_periodJ', 'data16_periodC', 'data16_periodF', 'data16_periodK'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to get data from files\n",
    "\n",
    "The datasets used in this notebook have already been filtered to include at least 2 photons per event, so that processing is quicker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data_from_files():\n",
    "\n",
    "\n",
    "    frames = [] # define empty list to hold data\n",
    "    for val in samples_list: # loop over each file\n",
    "        fileString = tuple_path+val+\".root\" # file name to open\n",
    "        temp = read_file(fileString,val) # call the function read_file defined below\n",
    "        frames.append(temp) # append dataframe returned from read_file to list of dataframes\n",
    "    data = ak.concatenate(frames) # concatenatelist of awkward arrays\n",
    "    \n",
    "    return data # return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to calculate diphoton invariant mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_myy(photon_pt,photon_eta,photon_phi,photon_e):\n",
    "    # construct awkward 4-vector array\n",
    "    p4 = vector.awk(ak.zip(dict(pt=photon_pt, eta=photon_eta, phi=photon_phi, E=photon_e)))\n",
    "    # calculate invariant mass of first 4 leptons\n",
    "    # [:, i] selects the i-th lepton in each event\n",
    "    # .M calculates the invariant mass\n",
    "    return (p4[:, 0] + p4[:, 1]).M * MeV\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='changing_cut'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cut on photon reconstruction quality\n",
    "# paper: \"Photon candidates are required to pass identification criteria\"\n",
    "def cut_photon_reconstruction(photon_isTightID):\n",
    "# isTightID==True means a photon identified as being well reconstructed\n",
    "# want to keep events where True for both photons\n",
    "# first photon is [0], 2nd photon is [1] etc\n",
    "    #return photon_isTightID[:,0]==True and photon_isTightID[:,1]==True\n",
    "    return (photon_isTightID[:,0] != 0) & (photon_isTightID[:,1] != 0)\n",
    "\n",
    "    \n",
    "# Cut on Transverse momentum\n",
    "# paper: \"The leading (sub-leading) photon candidate is required to have ET > 40 GeV (30 GeV)\"\n",
    "def cut_photon_pt(photon_pt):\n",
    "\n",
    "    return (photon_pt[:,0] >40 ) & (photon_pt[:,1]>30 )\n",
    "\n",
    "# Cut on energy isolation\n",
    "# paper: \"Photon candidates are required to have an isolation transverse energy of less than 4 GeV\"\n",
    "def cut_isolation_pt(photon_ptcone20):\n",
    "# want to keep events where isolation eT<4000 MeV\n",
    "    return (photon_ptcone20[:,0]<4) & (photon_ptcone20[:,1]<4 )\n",
    "\n",
    "# Cut on pseudorapidity in barrel/end-cap transition region\n",
    "# paper: \"excluding the calorimeter barrel/end-cap transition region 1.37 < |η| < 1.52\"\n",
    "def cut_photon_eta_transition(photon_eta):\n",
    "# want to keep events where modulus of photon_eta is outside the range 1.37 to 1.52\n",
    "    return ((np.abs(photon_eta[:,0])>1.52) | (np.abs(photon_eta[:,0])<1.37)) & ((np.abs(photon_eta[:,1])>1.52) | (np.abs(photon_eta[:,1])<1.37))\n",
    "\n",
    "\n",
    "def cut_n_photon(photon_n):\n",
    "# >=2\n",
    "    return photon_n>=2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='applying_cut'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Applying a cut \n",
    "\n",
    "If you add a cut: Cell -> Run All Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import uproot\n",
    "import awkward as ak\n",
    "\n",
    "# Initialize global cutflow dictionary\n",
    "global_cutflow = {\n",
    "    \"Before Cuts\": 0,\n",
    "    \"After photon reconstruction cut\": 0,\n",
    "    \"After photon pt cut\": 0,\n",
    "    \"After photon isolation cut\": 0,\n",
    "    \"After photon eta transition cut\": 0\n",
    "}\n",
    "\n",
    "def read_file(path, sample, fraction=1.0):\n",
    "    start = time.time()\n",
    "    print(f\"\\tProcessing: {sample}\")\n",
    "    data_all = []\n",
    "\n",
    "    # Initialize local cutflow dictionary\n",
    "    local_cutflow = {\n",
    "        \"Before Cuts\": 0,\n",
    "        \"After photon reconstruction cut\": 0,\n",
    "        \"After photon pt cut\": 0,\n",
    "        \"After photon isolation cut\": 0,\n",
    "        \"After photon eta transition cut\": 0\n",
    "    }\n",
    "\n",
    "    with uproot.open(path + \":analysis\") as tree:\n",
    "        numevents = tree.num_entries\n",
    "        for data in tree.iterate([\"photon_pt\", \"photon_eta\", \"photon_phi\", \"photon_e\",\n",
    "                                  \"photon_isTightID\", \"photon_ptcone20\"],\n",
    "                                 library=\"ak\",\n",
    "                                 entry_stop=int(numevents*fraction)):\n",
    "            \n",
    "            local_cutflow[\"Before Cuts\"] += len(data)\n",
    "            global_cutflow[\"Before Cuts\"] += len(data)\n",
    "\n",
    "            data = data[cut_photon_reconstruction(data.photon_isTightID)]\n",
    "            local_cutflow[\"After photon reconstruction cut\"] += len(data)\n",
    "            global_cutflow[\"After photon reconstruction cut\"] += len(data)\n",
    "\n",
    "            data = data[cut_photon_pt(data.photon_pt)]\n",
    "            local_cutflow[\"After photon pt cut\"] += len(data)\n",
    "            global_cutflow[\"After photon pt cut\"] += len(data)\n",
    "\n",
    "            data = data[cut_isolation_pt(data.photon_ptcone20)]\n",
    "            local_cutflow[\"After photon isolation cut\"] += len(data)\n",
    "            global_cutflow[\"After photon isolation cut\"] += len(data)\n",
    "\n",
    "            data = data[cut_photon_eta_transition(data.photon_eta)]\n",
    "            local_cutflow[\"After photon eta transition cut\"] += len(data)\n",
    "            global_cutflow[\"After photon eta transition cut\"] += len(data)\n",
    "\n",
    "            data['myy'] = calc_myy(data.photon_pt, data.photon_eta, data.photon_phi, data.photon_e)\n",
    "            data_all.append(data)\n",
    "\n",
    "            elapsed = time.time() - start\n",
    "            print(f\"\\t\\t nIn: {local_cutflow['Before Cuts']},\\t nOut: \\t{len(data)}\\t in {round(elapsed,1)}s\")\n",
    "\n",
    "    final_data = ak.concatenate(data_all, highlevel=True)\n",
    "\n",
    "    print(\"\\nLocal Cutflow Summary:\")\n",
    "    print(f\"{'Cut':<35}{'Entries':<15}{'Percentage Reduction':<25}\")\n",
    "    print(\"-\" * 75)\n",
    "    previous_entries = local_cutflow[\"Before Cuts\"]\n",
    "    for cut, entries in local_cutflow.items():\n",
    "        if cut == \"Before Cuts\":\n",
    "            print(f\"{cut:<35}{entries:<15}-\")\n",
    "        else:\n",
    "            reduction = (previous_entries - entries) / previous_entries * 100\n",
    "            print(f\"{cut:<35}{entries:<15}{reduction:.2f}%\")\n",
    "        previous_entries = entries\n",
    "    total_reduction = (local_cutflow[\"Before Cuts\"] - local_cutflow[\"After photon eta transition cut\"]) / local_cutflow[\"Before Cuts\"] * 100\n",
    "    print(\"-\" * 75)\n",
    "    print(f\"{'Total entries after all cuts':<35}{local_cutflow['After photon eta transition cut']:<15}{total_reduction:.2f}%\")\n",
    "\n",
    "    return final_data\n",
    "\n",
    "def print_global_cutflow():\n",
    "    print(\"\\nGlobal Cutflow Summary:\")\n",
    "    print(f\"{'Cut':<35}{'Entries':<15}{'Percentage Reduction':<25}\")\n",
    "    print(\"-\" * 75)\n",
    "    previous_entries = global_cutflow[\"Before Cuts\"]\n",
    "    for cut, entries in global_cutflow.items():\n",
    "        if cut == \"Before Cuts\":\n",
    "            print(f\"{cut:<35}{entries:<15}-\")\n",
    "        else:\n",
    "            reduction = (previous_entries - entries) / previous_entries * 100\n",
    "            print(f\"{cut:<35}{entries:<15}{reduction:.2f}%\")\n",
    "        previous_entries = entries\n",
    "    total_reduction = (global_cutflow[\"Before Cuts\"] - global_cutflow[\"After photon eta transition cut\"]) / global_cutflow[\"Before Cuts\"] * 100\n",
    "    print(\"-\" * 75)\n",
    "    print(f\"{'Total entries after all cuts':<35}{global_cutflow['After photon eta transition cut']:<15}{total_reduction:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where the processing happens (this will take some minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tProcessing: data15_periodD\n",
      "\t\t nIn: 11371,\t nOut: \t294\t in 0.2s\n",
      "\n",
      "Local Cutflow Summary:\n",
      "Cut                                Entries        Percentage Reduction     \n",
      "---------------------------------------------------------------------------\n",
      "Before Cuts                        11371          -\n",
      "After photon reconstruction cut    1103           90.30%\n",
      "After photon pt cut                512            53.58%\n",
      "After photon isolation cut         295            42.38%\n",
      "After photon eta transition cut    294            0.34%\n",
      "---------------------------------------------------------------------------\n",
      "Total entries after all cuts       294            97.41%\n",
      "\tProcessing: data15_periodG\n",
      "\t\t nIn: 164583,\t nOut: \t4782\t in 0.6s\n",
      "\n",
      "Local Cutflow Summary:\n",
      "Cut                                Entries        Percentage Reduction     \n",
      "---------------------------------------------------------------------------\n",
      "Before Cuts                        164583         -\n",
      "After photon reconstruction cut    16422          90.02%\n",
      "After photon pt cut                8018           51.18%\n",
      "After photon isolation cut         4819           39.90%\n",
      "After photon eta transition cut    4782           0.77%\n",
      "---------------------------------------------------------------------------\n",
      "Total entries after all cuts       4782           97.09%\n",
      "\tProcessing: data16_periodA\n",
      "\t\t nIn: 108353,\t nOut: \t3343\t in 0.9s\n",
      "\n",
      "Local Cutflow Summary:\n",
      "Cut                                Entries        Percentage Reduction     \n",
      "---------------------------------------------------------------------------\n",
      "Before Cuts                        108353         -\n",
      "After photon reconstruction cut    10070          90.71%\n",
      "After photon pt cut                5630           44.09%\n",
      "After photon isolation cut         3359           40.34%\n",
      "After photon eta transition cut    3343           0.48%\n",
      "---------------------------------------------------------------------------\n",
      "Total entries after all cuts       3343           96.91%\n",
      "\tProcessing: data16_periodD\n",
      "\t\t nIn: 588911,\t nOut: \t19151\t in 1.9s\n",
      "\n",
      "Local Cutflow Summary:\n",
      "Cut                                Entries        Percentage Reduction     \n",
      "---------------------------------------------------------------------------\n",
      "Before Cuts                        588911         -\n",
      "After photon reconstruction cut    57411          90.25%\n",
      "After photon pt cut                31509          45.12%\n",
      "After photon isolation cut         19253          38.90%\n",
      "After photon eta transition cut    19151          0.53%\n",
      "---------------------------------------------------------------------------\n",
      "Total entries after all cuts       19151          96.75%\n",
      "\tProcessing: data16_periodG\n",
      "\t\t nIn: 512073,\t nOut: \t15937\t in 1.7s\n",
      "\n",
      "Local Cutflow Summary:\n",
      "Cut                                Entries        Percentage Reduction     \n",
      "---------------------------------------------------------------------------\n",
      "Before Cuts                        512073         -\n",
      "After photon reconstruction cut    49710          90.29%\n",
      "After photon pt cut                26742          46.20%\n",
      "After photon isolation cut         16002          40.16%\n",
      "After photon eta transition cut    15937          0.41%\n",
      "---------------------------------------------------------------------------\n",
      "Total entries after all cuts       15937          96.89%\n",
      "\tProcessing: data16_periodL\n",
      "\t\t nIn: 800600,\t nOut: \t25391\t in 2.8s\n",
      "\n",
      "Local Cutflow Summary:\n",
      "Cut                                Entries        Percentage Reduction     \n",
      "---------------------------------------------------------------------------\n",
      "Before Cuts                        800600         -\n",
      "After photon reconstruction cut    78008          90.26%\n",
      "After photon pt cut                41450          46.86%\n",
      "After photon isolation cut         25519          38.43%\n",
      "After photon eta transition cut    25391          0.50%\n",
      "---------------------------------------------------------------------------\n",
      "Total entries after all cuts       25391          96.83%\n",
      "\tProcessing: data15_periodE\n",
      "\t\t nIn: 99884,\t nOut: \t2852\t in 0.4s\n",
      "\n",
      "Local Cutflow Summary:\n",
      "Cut                                Entries        Percentage Reduction     \n",
      "---------------------------------------------------------------------------\n",
      "Before Cuts                        99884          -\n",
      "After photon reconstruction cut    9908           90.08%\n",
      "After photon pt cut                4815           51.40%\n",
      "After photon isolation cut         2880           40.19%\n",
      "After photon eta transition cut    2852           0.97%\n",
      "---------------------------------------------------------------------------\n",
      "Total entries after all cuts       2852           97.14%\n",
      "\tProcessing: data15_periodH\n",
      "\t\t nIn: 61052,\t nOut: \t1754\t in 0.3s\n",
      "\n",
      "Local Cutflow Summary:\n",
      "Cut                                Entries        Percentage Reduction     \n",
      "---------------------------------------------------------------------------\n",
      "Before Cuts                        61052          -\n",
      "After photon reconstruction cut    6141           89.94%\n",
      "After photon pt cut                2950           51.96%\n",
      "After photon isolation cut         1769           40.03%\n",
      "After photon eta transition cut    1754           0.85%\n",
      "---------------------------------------------------------------------------\n",
      "Total entries after all cuts       1754           97.13%\n",
      "\tProcessing: data16_periodB\n",
      "\t\t nIn: 237575,\t nOut: \t7634\t in 0.8s\n",
      "\n",
      "Local Cutflow Summary:\n",
      "Cut                                Entries        Percentage Reduction     \n",
      "---------------------------------------------------------------------------\n",
      "Before Cuts                        237575         -\n",
      "After photon reconstruction cut    22955          90.34%\n",
      "After photon pt cut                12563          45.27%\n",
      "After photon isolation cut         7681           38.86%\n",
      "After photon eta transition cut    7634           0.61%\n",
      "---------------------------------------------------------------------------\n",
      "Total entries after all cuts       7634           96.79%\n",
      "\tProcessing: data16_periodE\n",
      "\t\t nIn: 181420,\t nOut: \t5927\t in 0.6s\n",
      "\n",
      "Local Cutflow Summary:\n",
      "Cut                                Entries        Percentage Reduction     \n",
      "---------------------------------------------------------------------------\n",
      "Before Cuts                        181420         -\n",
      "After photon reconstruction cut    17939          90.11%\n",
      "After photon pt cut                9828           45.21%\n",
      "After photon isolation cut         5962           39.34%\n",
      "After photon eta transition cut    5927           0.59%\n",
      "---------------------------------------------------------------------------\n",
      "Total entries after all cuts       5927           96.73%\n",
      "\tProcessing: data16_PeriodI\n",
      "\t\t nIn: 730763,\t nOut: \t23364\t in 2.7s\n",
      "\n",
      "Local Cutflow Summary:\n",
      "Cut                                Entries        Percentage Reduction     \n",
      "---------------------------------------------------------------------------\n",
      "Before Cuts                        730763         -\n",
      "After photon reconstruction cut    71280          90.25%\n",
      "After photon pt cut                38359          46.19%\n",
      "After photon isolation cut         23486          38.77%\n",
      "After photon eta transition cut    23364          0.52%\n",
      "---------------------------------------------------------------------------\n",
      "Total entries after all cuts       23364          96.80%\n",
      "\tProcessing: data15_periodF\n",
      "\t\t nIn: 71665,\t nOut: \t2048\t in 0.3s\n",
      "\n",
      "Local Cutflow Summary:\n",
      "Cut                                Entries        Percentage Reduction     \n",
      "---------------------------------------------------------------------------\n",
      "Before Cuts                        71665          -\n",
      "After photon reconstruction cut    7116           90.07%\n",
      "After photon pt cut                3483           51.05%\n",
      "After photon isolation cut         2067           40.65%\n",
      "After photon eta transition cut    2048           0.92%\n",
      "---------------------------------------------------------------------------\n",
      "Total entries after all cuts       2048           97.14%\n",
      "\tProcessing: data15_periodJ\n",
      "\t\t nIn: 329733,\t nOut: \t9498\t in 1.0s\n",
      "\n",
      "Local Cutflow Summary:\n",
      "Cut                                Entries        Percentage Reduction     \n",
      "---------------------------------------------------------------------------\n",
      "Before Cuts                        329733         -\n",
      "After photon reconstruction cut    33310          89.90%\n",
      "After photon pt cut                16115          51.62%\n",
      "After photon isolation cut         9582           40.54%\n",
      "After photon eta transition cut    9498           0.88%\n",
      "---------------------------------------------------------------------------\n",
      "Total entries after all cuts       9498           97.12%\n",
      "\tProcessing: data16_periodC\n",
      "\t\t nIn: 386271,\t nOut: \t12338\t in 1.5s\n",
      "\n",
      "Local Cutflow Summary:\n",
      "Cut                                Entries        Percentage Reduction     \n",
      "---------------------------------------------------------------------------\n",
      "Before Cuts                        386271         -\n",
      "After photon reconstruction cut    37230          90.36%\n",
      "After photon pt cut                20539          44.83%\n",
      "After photon isolation cut         12410          39.58%\n",
      "After photon eta transition cut    12338          0.58%\n",
      "---------------------------------------------------------------------------\n",
      "Total entries after all cuts       12338          96.81%\n",
      "\tProcessing: data16_periodF\n",
      "\t\t nIn: 425286,\t nOut: \t13568\t in 1.4s\n",
      "\n",
      "Local Cutflow Summary:\n",
      "Cut                                Entries        Percentage Reduction     \n",
      "---------------------------------------------------------------------------\n",
      "Before Cuts                        425286         -\n",
      "After photon reconstruction cut    41757          90.18%\n",
      "After photon pt cut                22288          46.62%\n",
      "After photon isolation cut         13632          38.84%\n",
      "After photon eta transition cut    13568          0.47%\n",
      "---------------------------------------------------------------------------\n",
      "Total entries after all cuts       13568          96.81%\n",
      "\tProcessing: data16_periodK\n",
      "\t\t nIn: 289333,\t nOut: \t9093\t in 0.9s\n",
      "\n",
      "Local Cutflow Summary:\n",
      "Cut                                Entries        Percentage Reduction     \n",
      "---------------------------------------------------------------------------\n",
      "Before Cuts                        289333         -\n",
      "After photon reconstruction cut    27869          90.37%\n",
      "After photon pt cut                15005          46.16%\n",
      "After photon isolation cut         9138           39.10%\n",
      "After photon eta transition cut    9093           0.49%\n",
      "---------------------------------------------------------------------------\n",
      "Total entries after all cuts       9093           96.86%\n",
      "Time taken: 19.7s\n"
     ]
    }
   ],
   "source": [
    "#pname = '/project/etp1/dkoch/ATLASOpenData/ntuples-data-samples/data15_allyear.root'\n",
    "start = time.time() # time at start of whole processing\n",
    "data = get_data_from_files() # process all files\n",
    "#data = read_file_new(pname) #\n",
    "elapsed = time.time() - start # time after whole processing\n",
    "print(\"Time taken: \"+str(round(elapsed,1))+\"s\") # print total time taken to process every file\n",
    "print_global_cutflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Global Cutflow Summary:\n",
      "Cut                                Entries        Percentage Reduction     \n",
      "---------------------------------------------------------------------------\n",
      "Before Cuts                        4998873        -\n",
      "After photon reconstruction cut    488229         90.23%\n",
      "After photon pt cut                259806         46.79%\n",
      "After photon isolation cut         157854         39.24%\n",
      "After photon eta transition cut    156974         0.56%\n",
      "---------------------------------------------------------------------------\n",
      "Total entries after all cuts       156974         96.86%\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='plotting'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting\n",
    "If you only want a make a change in the plot: Cell -> Run All Below\n",
    "\n",
    "Define function to plot the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from awkward import Array, to_list\n",
    "from lmfit.models import PolynomialModel, GaussianModel\n",
    "from matplotlib.ticker import AutoMinorLocator, MaxNLocator\n",
    "\n",
    "def plot_data(data):\n",
    "    # Ensure data is an awkward array\n",
    "    myy_data = Array(data['myy']) if not isinstance(data['myy'], Array) else data['myy']\n",
    "    \n",
    "    # Check for NaN values\n",
    "    myy_np = to_list(myy_data)\n",
    "    if np.any(np.isnan(myy_np)):\n",
    "        raise ValueError(\"Input data contains NaN values!\")\n",
    "\n",
    "    xmin = 100  # GeV\n",
    "    xmax = 160  # GeV\n",
    "    step_size = 2  # GeV\n",
    "    \n",
    "    bin_edges = np.arange(start=xmin, stop=xmax + step_size, step=step_size)\n",
    "    bin_centres = np.arange(start=xmin + step_size / 2, stop=xmax + step_size / 2, step=step_size)\n",
    "    \n",
    "    print(\"bin_centres is:\", bin_centres)\n",
    "\n",
    "    # Convert awkward array to a numpy array for histogram\n",
    "    data_x, _ = np.histogram(myy_np, bins=bin_edges)  # histogram the data\n",
    "\n",
    "    print('data myy is:', myy_np)\n",
    "    print(\"data_x is:\", data_x)\n",
    "    \n",
    "    # Check for NaN values in histogram data\n",
    "    if np.any(np.isnan(data_x)):\n",
    "        raise ValueError(\"Histogram data contains NaN values!\")\n",
    "\n",
    "    data_x_errors = np.sqrt(data_x)  # statistical error on the data\n",
    "\n",
    "    # Avoid fitting if all data_x is zero (which leads to NaNs)\n",
    "    if np.all(data_x == 0):\n",
    "        raise ValueError(\"All histogram counts are zero; cannot fit a model.\")\n",
    "\n",
    "    # Fit models\n",
    "    polynomial_mod = PolynomialModel(4)  # 4th order polynomial\n",
    "    gaussian_mod = GaussianModel()  # Gaussian\n",
    "\n",
    "    # Set initial guesses for the parameters of the polynomial model\n",
    "    pars = polynomial_mod.guess(data_x, x=bin_centres, c0=data_x.max(), c1=20000, c2=1000, c3=0, c4=0)\n",
    "    print('data_x.max() is:', data_x.max())\n",
    "\n",
    "    # Set initial gues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data['myy'] #invriant masses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the function to plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='going_further'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What can you do to explore this analysis?\n",
    "\n",
    "* Increase the fraction of data used in '[Lumi, fraction, file path](#fraction)'\n",
    "* Use data_B, data_C and data_D in '[Samples](#samples)'\n",
    "* Check how many events are being thrown away by each cut in '[Applying a cut](#applying_cut)'\n",
    "* Add more cuts from the [Higgs discovery paper](https://www.sciencedirect.com/science/article/pii/S037026931200857X#se0090) in '[Changing a cut](#changing_cut)' and '[Applying a cut](#applying_cut)'\n",
    "* Find the reduced chi-squared for the fit in '[Plotting](#plotting)'\n",
    "* Find the mean of the fitted Gaussian in '[Plotting](#plotting)'\n",
    "* Find the width of the fitted Gaussian in '[Plotting](#plotting)'\n",
    "* Try different initial guesses for the parameters of the fit in '[Plotting](#plotting)'\n",
    "* Try different functions for the fit in '[Plotting](#plotting)'\n",
    "* Your idea!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(data):   \n",
    "    # Define your range, binning, and calculate the histogram\n",
    "    xmin = 100 # GeV\n",
    "    xmax = 160 # GeV\n",
    "    step_size = 2 # GeV\n",
    "    \n",
    "    bin_edges = np.arange(start=xmin, stop=xmax + step_size, step=step_size)\n",
    "    bin_centres = np.arange(start=xmin + step_size/2, stop=xmax + step_size/2, step=step_size)\n",
    "\n",
    "    data_x, _ = np.histogram(data['myy'], bins=bin_edges)\n",
    "    data_x_errors = np.sqrt(data_x)  # Statistical error on the data\n",
    "\n",
    "    # Define the polynomial and Gaussian models\n",
    "    polynomial_mod = PolynomialModel(4)  # 4th order polynomial\n",
    "    gaussian_mod = GaussianModel()\n",
    "\n",
    "    # Initial parameter guesses\n",
    "    pars = polynomial_mod.guess(data_x, x=bin_centres, c0=data_x.max(), c1=0, c2=0, c3=0, c4=0)\n",
    "    pars += gaussian_mod.guess(data_x, x=bin_centres, amplitude=1600, center=125, sigma=2)\n",
    "\n",
    "    # Combine the models\n",
    "    model = polynomial_mod + gaussian_mod\n",
    "\n",
    "    # Fit the model to the data\n",
    "    out = model.fit(data_x, pars, x=bin_centres, weights=1/data_x_errors)\n",
    "\n",
    "    # Check if fit was successful\n",
    "    if out.success:\n",
    "        print(\"Fit was successful!\")\n",
    "    else:\n",
    "        print(\"Fit failed!\")\n",
    "\n",
    "    # Extract and print fit parameters\n",
    "    params_dict = out.params.valuesdict()  # Get the fitted parameter values as a dictionary\n",
    "    for param, value in params_dict.items():\n",
    "        print(f\"{param} = {value}\")\n",
    "    \n",
    "    # Optional: return the parameters for further use\n",
    "    return params_dict\n",
    "\n",
    "    # ... (rest of your plotting code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params, out = plot_data(data)\n",
    "print(\"Fitted parameters: \", params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import awkward as ak\n",
    "\n",
    "# Assuming 'data_filtered' is your filtered DataFrame from the previous step\n",
    "# First, flatten the 'photon_pt' lists into a 1D array using Awkward\n",
    "all_photon_pt = ak.flatten(data['photon_e']).to_list()\n",
    "\n",
    "# Now plot the distribution of photon transverse momenta\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(all_photon_pt, bins=60, range = (100,160), color='b', alpha=0.7)\n",
    "\n",
    "# Adding labels and title\n",
    "plt.title('Distribution of Photon Energy', fontsize=14)\n",
    "plt.xlabel('Photon_e [GeV]', fontsize=12)\n",
    "plt.ylabel('Number of Events', fontsize=12)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import awkward as ak\n",
    "\n",
    "# Assuming 'data_filtered' is your filtered DataFrame from the previous step\n",
    "# Flatten the 'photon_pt' lists into 1D arrays using Awkward\n",
    "all_photon_pt1 = ak.flatten(data['photon_pt'][0]).to_list()\n",
    "all_photon_pt2 = ak.flatten(data['photon_pt'][1]).to_list()\n",
    "\n",
    "# Create a figure with two subplots (1 row, 2 columns)\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot for the first photon\n",
    "plt.subplot(1, 2, 1)  # 1 row, 2 columns, first plot\n",
    "plt.hist(all_photon_pt1, bins=60, range=(0, 250), color='b', alpha=0.7)\n",
    "plt.title('Photon 1: Transverse Momentum', fontsize=14)\n",
    "plt.xlabel('Photon pT [GeV]', fontsize=12)\n",
    "plt.ylabel('%', fontsize=12)\n",
    "\n",
    "# Plot for the second photon\n",
    "plt.subplot(1, 2, 2)  # 1 row, 2 columns, second plot\n",
    "plt.hist(all_photon_pt2, bins=60, range=(0, 250), color='r', alpha=0.7)\n",
    "plt.title('Photon 2: Transverse Momentum', fontsize=14)\n",
    "plt.xlabel('Photon pT [GeV]', fontsize=12)\n",
    "plt.ylabel('%', fontsize=12)\n",
    "\n",
    "# Adjust the layout to make sure plots don't overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import awkward as ak\n",
    "\n",
    "# Assuming 'data_filtered' is your filtered DataFrame from the previous step\n",
    "# Flatten the 'photon_pt' lists into 1D arrays using Awkward\n",
    "all_photon_pt1 = ak.flatten(data['photon_eta'][0]).to_list()\n",
    "all_photon_pt2 = ak.flatten(data['photon_eta'][1]).to_list()\n",
    "\n",
    "# Create a figure with two subplots (1 row, 2 columns)\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot for the first photon\n",
    "plt.subplot(1, 2, 1)  # 1 row, 2 columns, first plot\n",
    "plt.hist(all_photon_pt1, bins=8, range=(-4, 4), color='b', alpha=0.7)\n",
    "plt.title('Photon 1: Eta', fontsize=14)\n",
    "plt.xlabel('Photon eta  ', fontsize=12)\n",
    "plt.ylabel('%', fontsize=12)\n",
    "\n",
    "# Plot for the second photon\n",
    "plt.subplot(1, 2, 2)  # 1 row, 2 columns, second plot\n",
    "plt.hist(all_photon_pt2, bins=8, range=(-4, 4), color='r', alpha=0.7)\n",
    "plt.title('Photon 2: Eta', fontsize=14)\n",
    "plt.xlabel('Photon eta  ]', fontsize=12)\n",
    "plt.ylabel('%', fontsize=12)\n",
    "\n",
    "# Adjust the layout to make sure plots don't overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import awkward as ak\n",
    "\n",
    "# Assuming 'data_filtered' is your filtered DataFrame from the previous step\n",
    "# Flatten the 'photon_pt' lists into 1D arrays using Awkward\n",
    "all_photon_pt1 = ak.flatten(data['photon_ptcone20'][0]).to_list()\n",
    "all_photon_pt2 = ak.flatten(data['photon_ptcone20'][1]).to_list()\n",
    "\n",
    "# Create a figure with two subplots (1 row, 2 columns)\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot for the first photon\n",
    "plt.subplot(1, 2, 1)  # 1 row, 2 columns, first plot\n",
    "plt.hist(all_photon_pt1, bins=10, range=(0, 10), color='b', alpha=0.7)\n",
    "plt.title('Photon 1: ptcone20', fontsize=14)\n",
    "plt.xlabel('ptcone20 value  ', fontsize=12)\n",
    "plt.ylabel('%', fontsize=12)\n",
    "\n",
    "# Plot for the second photon\n",
    "plt.subplot(1, 2, 2)  # 1 row, 2 columns, second plot\n",
    "plt.hist(all_photon_pt2, bins=10, range=(0, 10), color='r', alpha=0.7)\n",
    "plt.title('Photon 2: ptcone20', fontsize=14)\n",
    "plt.xlabel('ptcone20 value ', fontsize=12)\n",
    "plt.ylabel('%', fontsize=12)\n",
    "\n",
    "# Adjust the layout to make sure plots don't overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import awkward as ak\n",
    "\n",
    "# Assuming 'data_filtered' is your filtered DataFrame from the previous step\n",
    "# Flatten the 'photon_pt' lists into 1D arrays using Awkward\n",
    "all_photon_pt1 = ak.flatten(data['photon_phi'][0]).to_list()\n",
    "all_photon_pt2 = ak.flatten(data['photon_phi'][1]).to_list()\n",
    "\n",
    "# Create a figure with two subplots (1 row, 2 columns)\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot for the first photon\n",
    "plt.subplot(1, 2, 1)  # 1 row, 2 columns, first plot\n",
    "plt.hist(all_photon_pt1, bins=10, range=(0, 10), color='b', alpha=0.7)\n",
    "plt.title('Photon 1: phi', fontsize=14)\n",
    "plt.xlabel('Photon phi  ', fontsize=12)\n",
    "plt.ylabel('%', fontsize=12)\n",
    "\n",
    "# Plot for the second photon\n",
    "plt.subplot(1, 2, 2)  # 1 row, 2 columns, second plot\n",
    "plt.hist(all_photon_pt2, bins=10, range=(0, 10), color='r', alpha=0.7)\n",
    "plt.title('Photon 2: phi', fontsize=14)\n",
    "plt.xlabel('Photon phi  ]', fontsize=12)\n",
    "plt.ylabel('%', fontsize=12)\n",
    "\n",
    "# Adjust the layout to make sure plots don't overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['photon_isTightID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
